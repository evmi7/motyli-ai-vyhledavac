{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmN2Y3Bj6x+jQVoMBSOPN0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evmi7/motyli-ai-vyhledavac/blob/main/GradioClipApp-Motyli.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RhM8qd_SYUo"
      },
      "outputs": [],
      "source": [
        "# 游뿺 Gradio aplikace: Vyhled치v치n칤 podobn칳ch mot칳l콢 pomoc칤 CLIP\n",
        "# Vyhled치v치n칤 podle textu nebo obr치zku\n",
        "\n",
        "import gradio as gr\n",
        "import clip\n",
        "import torch\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "from datasets import load_dataset\n",
        "\n",
        "# 游늰 Pokus o na캜ten칤 embedding콢\n",
        "embedding_path = \"butterfly_embeddings.pt\"\n",
        "if os.path.exists(embedding_path):\n",
        "    with open(embedding_path, \"rb\") as f:\n",
        "        data = pickle.load(f)\n",
        "        image_embeddings = data[\"embeddings\"]\n",
        "        image_labels = data[\"tags\"]\n",
        "        image_ids = data[\"paths\"]\n",
        "        label_names = data.get(\"label_names\", None)\n",
        "    embeddings_loaded = True\n",
        "else:\n",
        "    embeddings_loaded = False\n",
        "\n",
        "# 游 Na캜ten칤 CLIP modelu\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "# 游늱 Na캜ten칤 datasetu\n",
        "hf_dataset = load_dataset(\"imagefolder\", repo_id=\"evmi7/motyli-butterflays-full2\", split=\"train\")\n",
        "\n",
        "# 丘뒲잺 Funkce vyhled치v치n칤 podle textu\n",
        "\n",
        "def search_by_text(query, top_k=5):\n",
        "    if not embeddings_loaded:\n",
        "        return None, [None] * top_k\n",
        "\n",
        "    text = clip.tokenize([query]).to(device)\n",
        "    with torch.no_grad():\n",
        "        text_features = model.encode_text(text)\n",
        "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    similarities = (image_embeddings @ text_features.cpu().numpy().T).squeeze()\n",
        "    best_indices = similarities.argsort()[-top_k:][::-1]\n",
        "    images = [hf_dataset[int(image_ids[i])][\"image\"] for i in best_indices]\n",
        "    captions = [label_names[image_labels[i]] if label_names else str(image_labels[i]) for i in best_indices]\n",
        "    return None, list(zip(images, captions))\n",
        "\n",
        "# 游댌 Funkce vyhled치v치n칤 podle obr치zku\n",
        "\n",
        "def search_by_image(image, top_k=5):\n",
        "    if not embeddings_loaded:\n",
        "        return image, [None] * top_k\n",
        "\n",
        "    image_input = preprocess(image).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        image_features = model.encode_image(image_input)\n",
        "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    similarities = (image_embeddings @ image_features.cpu().numpy().T).squeeze()\n",
        "    best_indices = similarities.argsort()[-top_k:][::-1]\n",
        "    images = [hf_dataset[int(image_ids[i])][\"image\"] for i in best_indices]\n",
        "    captions = [label_names[image_labels[i]] if label_names else str(image_labels[i]) for i in best_indices]\n",
        "    return image, list(zip(images, captions))\n",
        "\n",
        "# 游늵 Rozhran칤 aplikace\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# 游뿺 Vyhled치v치n칤 mot칳l콢 pomoc칤 CLIP\")\n",
        "    gr.Markdown(\"Zadej anglick칳 textov칳 dotaz nebo nahraj obr치zek. Aplikace vr치t칤 nejpodobn캩j코칤 mot칳ly.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        text_input = gr.Textbox(label=\"Textov칳 dotaz\", placeholder=\"e.g. orange butterfly with black spots\")\n",
        "        image_input = gr.Image(type=\"pil\", label=\"Nebo nahraj referen캜n칤 obr치zek\")\n",
        "\n",
        "    search_button = gr.Button(\"Vyhledat\")\n",
        "    query_image = gr.Image(label=\"游닞 Referen캜n칤 obr치zek\", visible=False)\n",
        "    gallery = gr.Gallery(label=\"游꿠 Nejpodobn캩j코칤 mot칳li\", columns=5, rows=1)\n",
        "\n",
        "    def run_search(text, image):\n",
        "        if text:\n",
        "            return search_by_text(text)\n",
        "        elif image:\n",
        "            return search_by_image(image)\n",
        "        else:\n",
        "            return None, []\n",
        "\n",
        "    search_button.click(fn=run_search, inputs=[text_input, image_input], outputs=[query_image, gallery])\n",
        "\n",
        "    if not embeddings_loaded:\n",
        "        gr.Markdown(\"### 丘멆잺 Embeddingy zat칤m nejsou dostupn칠. Jakmile budou nahr치ny, aplikace za캜ne vracet v칳sledky.\")\n",
        "\n",
        "demo.launch()\n"
      ]
    }
  ]
}